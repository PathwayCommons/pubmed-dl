#!/usr/bin/env python
import json
import logging
import os
import time
from pathlib import Path

import typer
from dotenv import load_dotenv
from pydantic import BaseSettings

from pubmed_dl.ncbi import get_list_pmid, uids_to_docs

dot_env_filepath = Path(__file__).absolute().parent.parent / ".env"
load_dotenv(dot_env_filepath)


class Settings(BaseSettings):
    loglevel: str = os.getenv("LOGLEVEL", "INFO")


settings = Settings()
logging.basicConfig(level=settings.loglevel)


def main(start_date: str = typer.Argument(...,help = "The start date for data retrieval"), end_date: str = typer.Argument(...,help = "The end date for data retrieval"), request_file: str = typer.Argument(...,help = "The filename to write retrieved data to"), progress_bar: bool = typer.Option(True, help = "To display progress bar")):
    """
    The data to be downloaded is done in batches of articles from PubMed that are
    published between start_date and end_date.

    The request_file is where the retrieved data, is finally written to.
    """
    start_time = time.time()
    output_filepath: Path = Path(request_file)
    output_filepath.parents[0].mkdir(parents=True, exist_ok=True)
    pmids = get_list_pmid(start_date, end_date)
    with open(output_filepath, "w") as f:
        with typer.progressbar(length = len(pmids), label = "Processing") as progress:
            for batch in uids_to_docs(pmids):
                    for doc in batch:
                        f.write(f"{json.dumps(doc)}\n")
                        if progress_bar is True:
                            progress.update(1)
                    print("")
    logging.info(
        f"Done writing data from {start_date} to {end_date} onto file named: {output_filepath}"
    )
    duration = time.time() - start_time
    logging.info(f"Total run time for {len(pmids)} docs: {duration}s")


if __name__ == "__main__":
    typer.run(main)
